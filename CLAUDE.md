# Hippo - Complete Project Documentation

## Overview

Hippo ("The Memory That Never Forgets") is a local-first, cross-platform file organizer built with Rust + Tauri 2. It indexes files from local folders, extracts metadata, and provides fast search with semantic vector capabilities, AI-powered analysis, and real-time file watching.

**Architecture**: Rust core library + Tauri 2 desktop app with standalone HTML/JS UI (no build step)

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Module Documentation](#module-documentation)
3. [Data Models](#data-models)
4. [Tauri IPC Commands](#tauri-ipc-commands)
5. [Development Guide](#development-guide)
6. [Dependency Graph](#dependency-graph)

---

## Architecture Overview

```
hippo/
â”œâ”€â”€ Cargo.toml                    # Workspace config
â”œâ”€â”€ hippo-core/                   # Core Rust library
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ lib.rs                # Main Hippo struct & public API
â”‚       â”œâ”€â”€ models.rs             # All data types (Memory, Tag, Source, etc.)
â”‚       â”œâ”€â”€ error.rs              # HippoError enum
â”‚       â”œâ”€â”€ indexer/              # File discovery & metadata extraction
â”‚       â”‚   â”œâ”€â”€ mod.rs
â”‚       â”‚   â”œâ”€â”€ extractors.rs
â”‚       â”‚   â””â”€â”€ code_parser.rs
â”‚       â”œâ”€â”€ thumbnails/           # Image/video/PDF thumbnail generation
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ embeddings/           # Vector embeddings (Ollama/OpenAI/fallback)
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ storage/              # SQLite + Qdrant hybrid storage
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ search/               # Hybrid search (text + semantic + fuzzy)
â”‚       â”‚   â”œâ”€â”€ mod.rs
â”‚       â”‚   â””â”€â”€ advanced_filter.rs
â”‚       â”œâ”€â”€ ollama/               # Ollama AI integration
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ watcher/              # Real-time file system monitoring
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ qdrant/               # Vector database management
â”‚       â”‚   â”œâ”€â”€ mod.rs
â”‚       â”‚   â””â”€â”€ manager.rs
â”‚       â”œâ”€â”€ duplicates/           # Hash-based duplicate detection
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â”œâ”€â”€ graph/                # Knowledge graph (stub)
â”‚       â”‚   â””â”€â”€ mod.rs
â”‚       â””â”€â”€ sources/              # Cloud connector stubs
â”‚           â””â”€â”€ mod.rs
â”‚
â””â”€â”€ hippo-tauri/                  # Desktop application
    â”œâ”€â”€ Cargo.toml
    â”œâ”€â”€ tauri.conf.json           # Tauri config (withGlobalTauri: true)
    â”œâ”€â”€ capabilities/
    â”‚   â””â”€â”€ default.json          # Permissions (core, dialog, shell)
    â”œâ”€â”€ icons/                    # App icons
    â”œâ”€â”€ src/
    â”‚   â””â”€â”€ main.rs               # Tauri commands (IPC handlers)
    â””â”€â”€ ui/
        â””â”€â”€ dist/
            â””â”€â”€ index.html        # Complete standalone UI (no build step)
```

---

## Module Documentation

### 1. Indexer (`hippo-core/src/indexer/`)

**Purpose**: File discovery, metadata extraction, and background indexing orchestration.

**Key Components**:

- **File Discovery**: Uses `walkdir` to recursively scan directories
- **Batch Processing**: Processes files in parallel batches (configurable size)
- **Progress Tracking**: Real-time progress with ETA calculation
- **Metadata Extraction**: EXIF, code parsing, audio/video duration
- **Auto-tagging**: Optional AI-powered tagging via Ollama

**Architecture**:

```rust
// Indexer orchestrates the entire indexing pipeline
pub struct Indexer {
    storage: Arc<Storage>,
    embedder: Arc<Embedder>,
    config: IndexerConfig,
    state: Arc<IndexingState>,    // Progress tracking
}

// Progress tracking with multiple stages
pub enum IndexingStage {
    Scanning,      // Walking directories
    Embedding,     // Generating embeddings
    Tagging,       // AI auto-tagging
    Complete,
}
```

**Supported File Types** (70+ extensions):
- Images: jpg, jpeg, png, gif, webp, bmp, tiff, heic, heif, raw, cr2, nef
- Videos: mp4, mov, avi, mkv, webm, m4v
- Audio: mp3, wav, flac, m4a, ogg, aac
- Documents: pdf, doc, docx, txt, md, rtf, odt
- Code: rs, py, js, ts, jsx, tsx, go, java, c, cpp, rb, php, swift, kt, scala, sh, sql, html, css, json, yaml, toml, xml
- Archives: zip, tar, gz, 7z, rar

**Indexing Pipeline**:

```mermaid
graph LR
    A[Scan Directory] --> B[Filter Extensions]
    B --> C[Parallel Batch Processing]
    C --> D[Extract Metadata]
    D --> E[Generate Embedding]
    E --> F[Store in SQLite + Qdrant]
    F --> G[Auto-tag with AI]
    G --> H[Update Progress]
```

**Example Usage**:

```rust
// Queue a source for indexing
hippo.add_source(Source::Local {
    root_path: PathBuf::from("/path/to/photos")
}).await?;

// Monitor progress
let progress = hippo.get_indexing_progress().await?;
println!("Progress: {}%", progress.percentage());
```

**Key Files**:
- `mod.rs`: Main indexer orchestration, progress tracking, batch processing
- `extractors.rs`: EXIF extraction, document metadata, basic file stats
- `code_parser.rs`: AST parsing for Rust/Python/JavaScript/Go

---

### 2. Storage (`hippo-core/src/storage/mod.rs`)

**Purpose**: Hybrid storage layer combining SQLite (metadata) and Qdrant (vectors).

**Database Schema**:

```sql
-- Core memories table
CREATE TABLE memories (
    id TEXT PRIMARY KEY,
    path TEXT NOT NULL,
    source_json TEXT NOT NULL,
    kind_json TEXT NOT NULL,
    metadata_json TEXT NOT NULL,
    tags_json TEXT NOT NULL,
    embedding_id TEXT,
    connections_json TEXT NOT NULL,
    is_favorite INTEGER NOT NULL DEFAULT 0,
    created_at TEXT NOT NULL,
    modified_at TEXT NOT NULL,
    indexed_at TEXT NOT NULL,
    -- Searchable denormalized columns
    title TEXT,
    filename TEXT,
    extension TEXT,
    kind_name TEXT,
    tags_text TEXT
);

-- Indexes for fast queries
CREATE INDEX idx_memories_path ON memories(path);
CREATE INDEX idx_memories_created ON memories(created_at);
CREATE INDEX idx_memories_modified ON memories(modified_at);
CREATE INDEX idx_memories_kind ON memories(kind_name);
CREATE INDEX idx_memories_favorite ON memories(is_favorite);

-- Sources configuration
CREATE TABLE sources (
    id TEXT PRIMARY KEY,
    config_json TEXT NOT NULL,
    enabled INTEGER NOT NULL DEFAULT 1,
    last_sync TEXT
);

-- Tag index with counts
CREATE TABLE tags (
    name TEXT PRIMARY KEY,
    count INTEGER NOT NULL DEFAULT 0
);

-- Embeddings (SQLite fallback when Qdrant unavailable)
CREATE TABLE embeddings (
    memory_id TEXT PRIMARY KEY,
    embedding BLOB NOT NULL,  -- f32 array serialized
    model TEXT NOT NULL,
    created_at TEXT NOT NULL
);

-- Clusters for organization
CREATE TABLE clusters (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    kind TEXT NOT NULL,
    memory_ids_json TEXT NOT NULL,
    cover_id TEXT,
    auto_generated INTEGER NOT NULL DEFAULT 0,
    created_at TEXT NOT NULL,
    metadata_json TEXT NOT NULL
);
```

**Key Operations**:

```rust
// Memory CRUD
storage.upsert_memory(&memory).await?;
storage.get_memory(memory_id).await?;
storage.delete_memory(memory_id).await?;
storage.toggle_favorite(memory_id).await?;

// Tag operations
storage.add_tag(memory_id, tag).await?;
storage.remove_tag(memory_id, "tag_name").await?;
storage.list_tags().await?;  // Returns Vec<(String, u64)>

// Source management
storage.add_source(source).await?;
storage.list_sources().await?;
storage.remove_source(&source).await?;

// Search operations (optimized SQL)
storage.search_with_tags(query, tags, kind, limit, offset).await?;
storage.count_search_results(query, tags, kind).await?;

// Vector operations (Qdrant or SQLite fallback)
storage.store_embedding_with_qdrant(id, embedding, model, kind).await?;
storage.search_vectors(query_embedding, kind_filter, limit).await?;
storage.find_similar(memory_id, limit).await?;
```

**Performance Features**:
- Denormalized search columns for fast LIKE queries
- JSON columns for flexible schema evolution
- Prepared statement caching
- Batch operations for indexing
- Cosine similarity in SQLite as fallback

---

### 3. Search (`hippo-core/src/search/`)

**Purpose**: Multi-modal search combining SQL, fuzzy matching, and semantic vectors.

**Search Modes**:

1. **Text Search**: Fast SQL LIKE queries on denormalized columns
2. **Semantic Search**: Vector similarity via Qdrant or SQLite fallback
3. **Hybrid Search**: Weighted combination of text + semantic
4. **Fuzzy Search**: Typo-tolerant with Levenshtein distance
5. **Natural Language**: Parses queries like "photos from last week"

**Search Architecture**:

```rust
pub struct Searcher {
    storage: Arc<Storage>,
    embedder: Arc<Embedder>,
    hybrid_config: HybridSearchConfig,  // Configurable weights
}

// Hybrid search scoring
pub struct HybridSearchConfig {
    pub semantic_weight: f32,  // 0.0 - 1.0 (default: 0.7)
    pub keyword_weight: f32,   // 0.0 - 1.0 (default: 0.3)
}
```

**Search Flow**:

```mermaid
graph TD
    A[Search Query] --> B{Query Type?}
    B -->|Text Only| C[SQL LIKE Search]
    B -->|Semantic| D[Generate Embedding]
    B -->|Hybrid| E[Both Paths]

    C --> F[Score by Relevance]
    D --> G[Qdrant Vector Search]
    E --> H[Combine Scores]

    F --> I[Apply Filters]
    G --> I
    H --> I

    I --> J[Sort by Score]
    J --> K[Return Results]
```

**Example Usage**:

```rust
// Basic text search
let results = searcher.search(SearchQuery {
    text: Some("vacation photos".to_string()),
    tags: vec![
        TagFilter { tag: "beach".to_string(), mode: Include }
    ],
    kinds: vec![MemoryKind::Image { .. }],
    date_range: Some(DateRange {
        start: Some(last_month),
        end: Some(now)
    }),
    limit: 50,
    offset: 0,
}).await?;

// Semantic search
let results = searcher.semantic_search("sunset beach", 20).await?;

// Hybrid search (best of both)
let results = searcher.hybrid_search("family photos", 30).await?;

// Natural language parsing
let parsed = searcher.parse_natural_query("photos from last week")?;
// Returns: ParsedQuery {
//     keywords: Some("photos"),
//     file_types: vec![MemoryKind::Image],
//     date_range: Some(DateRange { ... }),
// }
```

**Scoring Algorithm**:

```rust
// Text search scoring
if title_contains_query { score += 10.0; }
if title_starts_with_query { score += 5.0; }
if filename_contains_query { score += 8.0; }
if filename_starts_with_query { score += 4.0; }
if tag_contains_query { score += 7.0; }

// Recency boost
if age_days < 7 { score *= 1.1; }
else if age_days < 30 { score *= 1.05; }

// Hybrid scoring
final_score = (semantic_score * semantic_weight)
            + (keyword_score * keyword_weight);
```

**Fuzzy Matching**:
- Levenshtein distance calculation
- Character transposition detection
- Common substitutions (aâ†”e, iâ†”y, oâ†”u, câ†”k)
- Prefix matching bonus
- Jaccard similarity for character overlap

---

### 4. Embeddings (`hippo-core/src/embeddings/mod.rs`)

**Purpose**: Generate vector embeddings for semantic search.

**Supported Backends**:

1. **Ollama** (recommended): Local models like `nomic-embed-text` (768-dim)
2. **OpenAI**: `text-embedding-ada-002` (1536-dim) via API
3. **Hash Fallback**: Deterministic hash-based embeddings for offline use

**Architecture**:

```rust
pub struct Embedder {
    config: EmbedderConfig,
    ollama: Option<OllamaClient>,
    client: Client,  // For OpenAI API
}

pub enum EmbeddingProvider {
    Local,    // Hash-based fallback
    Ollama,   // Local Ollama server
    OpenAI,   // Cloud API
}
```

**Embedding Strategy by File Type**:

```rust
match memory.kind {
    MemoryKind::Image { .. } => {
        // Perceptual hash: resize to 16x16, extract RGB features
        // Normalize to 512-dim vector
    }
    MemoryKind::Code { language, .. } => {
        // Hash-based text embedding + language features
        // 768-dim with language one-hot encoding
    }
    MemoryKind::Document { .. } => {
        // Ollama/OpenAI if available, else hash-based
        // 1536-dim for compatibility
    }
    _ => {
        // Generic: path + tags + metadata
        // Hash-based 1536-dim
    }
}
```

**Example Usage**:

```rust
// Automatic embedding during indexing
let embedding = embedder.embed_memory(&memory).await?;
storage.store_embedding_with_qdrant(memory.id, &embedding, "text", &memory.kind).await?;

// Query embedding
let query_vec = embedder.embed_query("search text").await?;
let similar = storage.search_vectors(query_vec, None, 10).await?;

// Batch processing
let texts = vec!["doc1".to_string(), "doc2".to_string()];
let embeddings = embedder.embed_batch(&texts).await?;
```

**Hash-Based Fallback Algorithm**:

```rust
fn hash_embed(&self, text: &str, dim: usize) -> Vec<f32> {
    let tokens: Vec<&str> = text.split_whitespace().collect();
    let mut embedding = vec![0.0; dim];

    for (pos, token) in tokens.iter().enumerate() {
        let hash = simple_hash(token);
        let position_weight = 1.0 - (pos as f32 / tokens.len() as f32) * 0.5;

        // Multi-probe hashing (3 positions per token)
        for i in 0..3 {
            let idx = (hash + i * 7919) % dim;
            embedding[idx] += position_weight / (i + 1) as f32;
        }

        // Bigram features
        if pos > 0 {
            let bigram_hash = simple_hash(&format!("{}_{}", tokens[pos-1], token));
            embedding[bigram_hash % dim] += position_weight * 0.5;
        }
    }

    normalize(&mut embedding);  // L2 normalization
    embedding
}
```

---

### 5. Ollama Integration (`hippo-core/src/ollama/mod.rs`)

**Purpose**: Local AI capabilities (embeddings, chat, analysis) via Ollama.

**Recommended Models**:

```rust
// Fast models (~1-2GB) - quick responses
pub const FAST: &[&str] = &[
    "gemma2:2b",     // Google's Gemma2 2B - best quality/speed
    "qwen2.5:1.5b",  // Alibaba's Qwen - very fast
    "llama3.2:1b",   // Meta's smallest Llama
];

// Balanced models (~4-8GB) - good quality
pub const BALANCED: &[&str] = &[
    "gemma2:9b",     // High quality
    "llama3.2:3b",
    "qwen2.5:7b",
    "mistral:7b",
];

// Embeddings
pub const EMBEDDINGS: &[&str] = &[
    "nomic-embed-text",   // 768-dim, general purpose (recommended)
    "mxbai-embed-large",  // Higher quality
    "all-minilm",         // Fast, smaller dims
];

// Vision models
pub const VISION: &[&str] = &[
    "llava:7b",    // Image understanding
    "bakllava",
];
```

**Key Features**:

1. **Embeddings**: Local vector generation
2. **Text Generation**: Context-aware completions
3. **Chat**: Multi-turn conversations with streaming
4. **Document Analysis**: Structured JSON extraction
5. **Code Analysis**: Language-specific insights
6. **RAG**: Retrieval-augmented generation
7. **Vision**: Image captioning (llava)

**Example Usage**:

```rust
let ollama = OllamaClient::new();

// Check availability
if !ollama.is_available().await {
    ollama.pull_model("gemma2:2b").await?;
}

// Generate embeddings
let embedding = ollama.embed_single("some text").await?;

// Text generation
let response = ollama.generate(
    "Explain Rust ownership",
    Some("You are a helpful Rust tutor.")
).await?;

// Streaming chat
let messages = vec![
    ChatMessage::new("user", "What is Hippo?"),
];
ollama.stream_chat(&messages, cancel_token, |chunk| {
    print!("{}", chunk);  // Real-time output
}).await?;

// Document analysis (returns structured JSON)
let analysis = ollama.analyze_document(content, "report.pdf").await?;
// Returns: LocalAnalysis {
//     summary, key_topics, suggested_tags, document_type, language
// }

// Image captioning
let caption = ollama.caption_image(Path::new("photo.jpg")).await?;
```

**Streaming Protocol**:

```rust
// Stream responses in real-time with cancellation
pub async fn stream_chat<F>(
    &self,
    messages: &[ChatMessage],
    cancellation_token: CancellationToken,
    mut on_chunk: F,
) -> Result<String>
where
    F: FnMut(String) + Send,
{
    // Yields chunks as they arrive via callback
    // Supports user cancellation
    // Returns full response when done
}
```

---

### 6. Watcher (`hippo-core/src/watcher/mod.rs`)

**Purpose**: Real-time file system monitoring with automatic re-indexing using the `notify` crate.

**Architecture**:

```rust
pub struct FileWatcher {
    state: Arc<WatcherState>,
    event_tx: broadcast::Sender<WatchEvent>,
    storage: Arc<Storage>,
    indexer: Option<Arc<Indexer>>,  // For automatic re-indexing
    watcher: Option<RecommendedWatcher>,  // notify crate watcher
}

pub enum WatchEvent {
    Created { path, source },
    Modified { path, source },
    Deleted { path },
    Renamed { from, to, source },
    WatcherStarted,
    WatcherStopped,
    Error { message },
}
```

**Key Features**:

1. **Native File Watching**: Uses `notify` crate's `RecommendedWatcher` for platform-native file system events
2. **Automatic Re-indexing**: When a file is created or modified, the watcher automatically calls `indexer.index_single_file()` to update the index
3. **Automatic Deletion**: When a file is deleted, the corresponding memory is removed from the index
4. **Background Event Processing**: Events are processed in a dedicated async task
5. **Pause/Resume**: Can temporarily pause event processing while maintaining watchers

**Event Handling Flow**:

```mermaid
graph LR
    A[File System Change] --> B[notify event]
    B --> C[Background Task]
    C --> D{Event Type?}
    D -->|Create| E[index_single_file]
    D -->|Modify| F[remove + index_single_file]
    D -->|Delete| G[remove_memory_by_path]
```

**Example Usage**:

```rust
// Create watcher with indexer
let mut watcher = FileWatcher::new(storage.clone(), Some(500))?;
watcher.set_indexer(indexer.clone());  // Enable auto re-indexing

// Watch a path - automatically starts notify watcher
watcher.watch(&path, source).await?;

// Subscribe to events (optional - for custom handling)
let mut rx = watcher.subscribe();
tokio::spawn(async move {
    while let Ok(event) = rx.recv().await {
        match event {
            WatchEvent::Created { path, .. } => {
                println!("New file indexed: {:?}", path);
            }
            WatchEvent::Modified { path, .. } => {
                println!("File re-indexed: {:?}", path);
            }
            WatchEvent::Deleted { path } => {
                println!("File removed from index: {:?}", path);
            }
            _ => {}
        }
    }
});

// Pause/resume
watcher.pause().await?;
watcher.resume().await?;

// Get stats
let stats = watcher.stats().await;
println!("Watching {} paths, {} events processed",
    stats.total_watched_paths,
    stats.events_processed
);
```

---

### 7. Thumbnails (`hippo-core/src/thumbnails/mod.rs`)

**Purpose**: Fast thumbnail generation with disk + memory caching.

**Supported Formats**:
- Images: jpg, png, gif, bmp, webp, tiff, ico
- Videos: mp4, mov, avi, mkv, webm (via ffmpeg)
- PDFs: First page rendering (via pdfium)
- Office: docx, xlsx, pptx (embedded thumbnails)

**Caching Strategy**:

```rust
pub struct ThumbnailManager {
    cache_dir: PathBuf,  // Disk cache (~/.cache/Hippo/thumbnails)
    memory_cache: LruCache<String, CachedThumbnail>,  // Hot cache
    cache_memory_usage: usize,  // Current RAM usage
}

// Two-tier caching:
// 1. Memory cache: LRU, 500 entries, max 50MB
// 2. Disk cache: Persistent, SHA256-named files
```

**Thumbnail Generation**:

```mermaid
graph LR
    A[Request Thumbnail] --> B{In Memory Cache?}
    B -->|Yes| C[Return Immediately]
    B -->|No| D{On Disk?}
    D -->|Yes| E[Load from Disk]
    D -->|No| F{File Type?}

    F -->|Image| G[Resize to 256x256]
    F -->|Video| H[Extract Frame @ 2s]
    F -->|PDF| I[Render First Page]
    F -->|Office| J[Extract Embedded]

    G --> K[Save to Disk]
    H --> K
    I --> K
    J --> K

    K --> L[Add to Memory Cache]
    E --> L
    L --> C
```

**Example Usage**:

```rust
let thumbs = ThumbnailManager::new()?;

// Get or generate thumbnail
let thumb_data = thumbs.get_thumbnail_data(&image_path)?;

// Check if exists
if thumbs.has_thumbnail(&path) {
    let thumb_path = thumbs.get_thumbnail_path(&path);
}

// Video thumbnail (requires ffmpeg)
let thumb_path = thumbs.generate_video_thumbnail(&video_path)?;

// PDF thumbnail (requires pdfium)
let thumb_path = thumbs.generate_pdf_thumbnail(&pdf_path)?;

// Memory cache stats
let stats = thumbs.memory_cache_stats();
println!("Cache: {} entries, {} MB",
    stats.entries,
    stats.memory_bytes / 1024 / 1024
);

// Clear caches
thumbs.clear_memory_cache();
thumbs.clear_cache()?;  // Disk cache
```

**Cache Invalidation**:

```rust
// Smart invalidation: regenerate if source file modified
if thumbnail_path.exists() {
    let src_time = fs::metadata(image_path)?.modified()?;
    let thumb_time = fs::metadata(&thumbnail_path)?.modified()?;

    if thumb_time >= src_time {
        return Ok(thumbnail_path);  // Still valid
    }
}
// Regenerate if outdated
```

---

### 8. Qdrant Integration (`hippo-core/src/qdrant/`)

**Purpose**: Managed Qdrant vector database for semantic search.

**Collections**:

```rust
// Separate collections by embedding type
pub const COLLECTION_TEXT: &str = "hippo_text";      // 768-dim
pub const COLLECTION_IMAGE: &str = "hippo_image";    // 512-dim
pub const COLLECTION_CODE: &str = "hippo_code";      // 768-dim
```

**QdrantManager**:

```rust
pub struct QdrantManager {
    binary_path: PathBuf,
    data_dir: PathBuf,
    process: Arc<RwLock<Option<Child>>>,  // Managed process
    client: QdrantClient,
}

// Auto-download, start, and manage Qdrant
impl QdrantManager {
    pub async fn ensure_running(&self) -> Result<()>;
    pub async fn stop(&self) -> Result<()>;
    pub async fn status(&self) -> QdrantStatus;
    pub async fn cleanup(&self) -> Result<()>;  // Remove data
}
```

**Example Usage**:

```rust
let manager = QdrantManager::new(data_dir).await?;

// Start Qdrant (downloads if needed)
manager.ensure_running().await?;

// Check status
let status = manager.status().await;
println!("Running: {}, Collections: {}", status.running, status.collections);

// Use via Storage
let storage = Storage::new(&config).await?;
storage.store_embedding_with_qdrant(id, embedding, "text", &kind).await?;

// Vector search
let results = storage.search_vectors(query_embedding, Some(&kind), 10).await?;

// Shutdown
manager.stop().await?;
```

---

## Data Models

### Core Types

```rust
/// Unique identifier for any memory
pub type MemoryId = Uuid;

/// A Memory represents any indexed item
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Memory {
    pub id: MemoryId,
    pub path: PathBuf,
    pub source: Source,
    pub kind: MemoryKind,
    pub metadata: MemoryMetadata,
    pub tags: Vec<Tag>,
    pub embedding_id: Option<String>,
    pub connections: Vec<Connection>,
    pub is_favorite: bool,
    pub created_at: DateTime<Utc>,
    pub modified_at: DateTime<Utc>,
    pub indexed_at: DateTime<Utc>,
}

/// File type variants
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MemoryKind {
    Image { width: u32, height: u32, format: String },
    Video { duration_ms: u64, format: String },
    Audio { duration_ms: u64, format: String },
    Document { format: DocumentFormat, page_count: Option<u32> },
    Code { language: String, lines: u32 },
    Spreadsheet { sheet_count: u32 },
    Presentation { slide_count: u32 },
    Archive { item_count: u32 },
    Database,
    Folder,
    Unknown,
}

/// Where files come from
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Source {
    Local { root_path: PathBuf },
    GoogleDrive { account_id: String },  // stub
    ICloud { account_id: String },       // stub
    Dropbox { account_id: String },      // stub
    OneDrive { account_id: String },     // stub
    S3 { bucket: String, region: String },  // stub
    Custom { name: String },
}

/// Rich metadata extracted from files
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct MemoryMetadata {
    pub title: Option<String>,
    pub description: Option<String>,
    pub file_size: u64,
    pub mime_type: Option<String>,
    pub hash: Option<String>,  // SHA256 for deduplication

    // Media-specific
    pub exif: Option<ExifData>,
    pub dimensions: Option<(u32, u32)>,
    pub duration: Option<f64>,
    pub location: Option<GeoLocation>,

    // Document-specific
    pub text_preview: Option<String>,
    pub word_count: Option<u32>,

    // Code-specific
    pub code_info: Option<CodeInfo>,

    // AI-generated
    pub ai_summary: Option<String>,
    pub ai_tags: Vec<String>,
    pub ai_caption: Option<String>,

    pub custom: HashMap<String, serde_json::Value>,
}

/// Tags for organization
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Tag {
    pub name: String,
    pub kind: TagKind,
    pub confidence: u8,  // 0-100 for AI tags
}

pub enum TagKind {
    User,      // Manually added
    System,    // Auto-generated (type:image, folder:vacation)
    AI,        // AI-suggested
}

/// Search query structure
#[derive(Debug, Clone, Default)]
pub struct SearchQuery {
    pub text: Option<String>,
    pub tags: Vec<TagFilter>,
    pub sources: Vec<Source>,
    pub kinds: Vec<MemoryKind>,
    pub date_range: Option<DateRange>,
    pub sort: SortOrder,
    pub limit: usize,
    pub offset: usize,
}

pub struct TagFilter {
    pub tag: String,
    pub mode: TagFilterMode,  // Include or Exclude
}
```

---

## Tauri IPC Commands

All commands are async and return `Result<T, String>`.

| Command | Parameters | Returns | Description |
|---------|-----------|---------|-------------|
| `initialize` | - | `String` | Create Hippo instance, start Qdrant |
| `search` | `query: String, tags: Vec<String>` | `SearchResults` | Search memories with text and tags |
| `add_source` | `sourceType: String, path: String` | `String` | Add folder to index |
| `remove_source` | `path: String, deleteFiles: bool` | `String` | Remove source, optionally delete memories |
| `reindex_source` | `path: String` | `String` | Re-scan a folder |
| `get_sources` | - | `Vec<SourceConfig>` | List configured sources |
| `get_stats` | - | `StorageStats` | Get index statistics |
| `get_tags` | - | `Vec<(String, u64)>` | List all tags with counts |
| `add_tag` | `memoryId: String, tag: String` | `String` | Add tag to memory |
| `remove_tag` | `memoryId: String, tag: String` | `String` | Remove tag from memory |
| `toggle_favorite` | `memoryId: String` | `bool` | Star/unstar a file |
| `reset_index` | - | `String` | Delete all data and reinitialize |
| `open_file` | `path: String` | `String` | Open file with default app |
| `open_in_finder` | `path: String` | `String` | Reveal file in Finder/Explorer |
| `get_thumbnail` | `path: String` | `Vec<u8>` | Get or generate thumbnail |
| `get_indexing_progress` | - | `IndexingProgress` | Get current indexing status |
| `semantic_search` | `query: String, limit: usize` | `SearchResults` | Vector similarity search |
| `get_similar` | `memoryId: String, limit: usize` | `Vec<Memory>` | Find similar files |
| `chat_with_ai` | `messages: Vec<ChatMessage>` | `String` | Chat with Ollama/Claude |
| `analyze_file` | `path: String` | `LocalAnalysis` | AI analysis of file |

**Example IPC Usage (JavaScript)**:

```javascript
// Initialize
await invoke('initialize');

// Add source
await invoke('add_source', {
    sourceType: 'local',
    path: '/Users/me/Photos'
});

// Monitor progress
const progress = await invoke('get_indexing_progress');
console.log(`${progress.percentage}% complete`);

// Search
const results = await invoke('search', {
    query: 'vacation',
    tags: ['beach', 'summer']
});

// Semantic search
const similar = await invoke('semantic_search', {
    query: 'sunset photos',
    limit: 20
});

// Toggle favorite
const isFav = await invoke('toggle_favorite', {
    memoryId: '123e4567-e89b-12d3-a456-426614174000'
});

// Get thumbnail
const thumbData = await invoke('get_thumbnail', {
    path: '/path/to/image.jpg'
});
const blob = new Blob([new Uint8Array(thumbData)], { type: 'image/jpeg' });
const url = URL.createObjectURL(blob);

// Chat with AI
const response = await invoke('chat_with_ai', {
    messages: [
        { role: 'user', content: 'Explain this code file' }
    ]
});
```

---

## Development Guide

### Common Tasks

#### Adding a New File Type

1. **Update supported extensions** in `hippo-core/src/indexer/mod.rs`:

```rust
impl Default for IndexerConfig {
    fn default() -> Self {
        Self {
            supported_extensions: vec![
                // ... existing extensions ...
                "your_new_ext",  // Add here
            ]
        }
    }
}
```

2. **Add MemoryKind variant** in `hippo-core/src/models.rs`:

```rust
pub enum MemoryKind {
    // ... existing variants ...
    YourNewKind { custom_field: String },
}
```

3. **Update detection logic** in `indexer/mod.rs`:

```rust
fn detect_kind(path: &Path) -> Result<MemoryKind> {
    match ext.as_str() {
        // ... existing matches ...
        "your_ext" => MemoryKind::YourNewKind {
            custom_field: extract_custom_field(path)?
        },
    }
}
```

4. **Add metadata extraction** in `indexer/extractors.rs`:

```rust
pub fn extract_metadata(path: &Path, kind: &MemoryKind) -> Result<MemoryMetadata> {
    match kind {
        MemoryKind::YourNewKind { .. } => {
            // Extract specific metadata
        }
    }
}
```

#### Adding a New Search Filter

1. **Update SearchQuery** in `models.rs`:

```rust
pub struct SearchQuery {
    // ... existing fields ...
    pub your_filter: Option<YourFilterType>,
}
```

2. **Implement filter logic** in `search/mod.rs`:

```rust
pub async fn search(&self, query: SearchQuery) -> Result<SearchResults> {
    let mut results = self.get_base_results(&query).await?;

    // Apply your filter
    if let Some(filter) = &query.your_filter {
        results = results.into_iter()
            .filter(|m| your_filter_logic(m, filter))
            .collect();
    }

    Ok(results)
}
```

#### Adding a New Tauri Command

1. **Define command** in `hippo-tauri/src/main.rs`:

```rust
#[tauri::command]
async fn your_command(
    param: String,
    state: State<'_, AppState>,
) -> Result<YourReturnType, String> {
    let hippo_lock = state.hippo.read().await;
    let hippo = hippo_lock.as_ref().ok_or("Hippo not initialized")?;

    hippo.your_method(param).await
        .map_err(|e| e.to_string())
}
```

2. **Register command** in `main()`:

```rust
fn main() {
    tauri::Builder::default()
        .invoke_handler(tauri::generate_handler![
            // ... existing commands ...
            your_command,
        ])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
```

3. **Call from UI** in `index.html`:

```javascript
const result = await window.__TAURI__.invoke('your_command', {
    param: 'value'
});
```

#### Running Tests

```bash
# All tests
cargo test --workspace

# Specific module
cargo test -p hippo-core --lib storage

# With output
cargo test -- --nocapture

# Single test
cargo test test_name
```

#### Building for Release

```bash
# Build core library
cd hippo-core
cargo build --release

# Build desktop app
cd hippo-tauri
cargo tauri build

# Output locations:
# - macOS: target/release/bundle/dmg/
# - Windows: target/release/bundle/msi/
# - Linux: target/release/bundle/appimage/
```

---

## Dependency Graph

### Module Dependencies

```mermaid
graph TD
    A[lib.rs - Main Hippo API] --> B[indexer]
    A --> C[storage]
    A --> D[search]
    A --> E[watcher]

    B --> C
    B --> F[embeddings]
    B --> G[ollama]
    B --> H[extractors]

    D --> C
    D --> F

    E --> C

    C --> I[qdrant]

    F --> G

    J[thumbnails] -.optional.-> C
    K[duplicates] --> C

    L[models] --> A
    L --> B
    L --> C
    L --> D

    M[error] --> A
    M --> B
    M --> C
    M --> D
```

### Indexing Pipeline

```mermaid
sequenceDiagram
    participant User
    participant Hippo
    participant Indexer
    participant Storage
    participant Embedder
    participant Qdrant

    User->>Hippo: add_source(path)
    Hippo->>Indexer: queue_source(source)

    loop For each file
        Indexer->>Indexer: extract_metadata()
        Indexer->>Storage: upsert_memory(memory)
        Indexer->>Embedder: embed_memory(memory)
        Embedder->>Qdrant: store_vector(id, embedding)
        Indexer->>Hippo: update_progress()
    end

    Indexer->>Hippo: indexing_complete
    Hippo->>User: return success
```

### Search Flow

```mermaid
sequenceDiagram
    participant User
    participant UI
    participant Searcher
    participant Storage
    participant Qdrant

    User->>UI: enter search query
    UI->>Searcher: search(query)

    alt Semantic Search
        Searcher->>Searcher: embed_query()
        Searcher->>Qdrant: vector_search()
        Qdrant-->>Searcher: memory IDs + scores
    else Text Search
        Searcher->>Storage: search_with_tags()
        Storage-->>Searcher: matching memories
    end

    Searcher->>Searcher: score and rank
    Searcher->>UI: SearchResults
    UI->>User: display results
```

---

## Working Features

### Indexing
- Add local folders via native folder picker dialog
- Background indexing with progress tracking and ETA
- File discovery with 70+ supported extensions
- Parallel batch processing (configurable parallelism)
- EXIF extraction for images (camera, GPS, dimensions)
- Code parsing for Rust/Python/JS/Go (imports, exports, functions)
- Audio/video duration extraction (symphonia, ffmpeg)
- Hash-based duplicate detection
- Auto-tagging with Ollama AI

### Storage
- SQLite database with optimized indexes
- Qdrant vector database integration
- JSON columns for flexible schema
- Tag counting and management
- Source configuration persistence
- Export/import functionality

### Search
- Text search (filename, title, path, tags)
- Tag filtering (include/exclude modes)
- Semantic vector search via Qdrant
- Hybrid search (text + semantic combined)
- Fuzzy matching for typo tolerance
- Natural language query parsing
- Real-time search with debouncing
- Client-side type filtering
- Multiple sort options

### UI Features
- Grid and List view modes
- Type filter pills (All, Images, Videos, Audio, Code, Docs)
- Sort dropdown (Newest, Oldest, Name A-Z/Z-A, Size)
- Tag suggestions from search
- Tab key converts search text to tag filter
- Detail panel with file info
- Open file / Reveal in Finder buttons
- Keyboard shortcuts (Cmd+K to focus search, Esc to close)
- Image thumbnails (256x256 JPEG, cached)
- Video thumbnails (frame extraction via ffmpeg)
- Async thumbnail loading with placeholders

### AI Capabilities
- Local embeddings via Ollama (nomic-embed-text, mxbai-embed-large)
- Text generation (gemma2, llama3.2, qwen2.5, mistral)
- Streaming chat responses
- Document analysis with structured JSON output
- Code analysis with language-specific insights
- Image captioning with llava vision models
- RAG (Retrieval-Augmented Generation)
- Summarization
- Entity extraction

### File Watching
- Real-time file system monitoring (notify crate)
- Debounced event processing (configurable delay)
- Auto-update index on file changes
- Pause/resume functionality
- Event statistics tracking

### Thumbnails
- Two-tier caching (memory LRU + disk)
- Image thumbnails (all common formats)
- Video thumbnails (ffmpeg frame extraction)
- PDF thumbnails (pdfium first page rendering)
- Office document thumbnails (embedded extraction)
- Smart cache invalidation based on file mtime
- Memory-limited cache with auto-eviction

---

## Not Yet Implemented

### Cloud Sources
- Google Drive, iCloud, Dropbox OAuth flows
- Cloud file syncing
- S3 bucket integration

### Advanced Features
- Face clustering (without recognition)
- Knowledge graph visualization (D3.js)
- Full-text search with FTS5
- Advanced filters (file size ranges, date comparisons)
- Batch operations (multi-select, bulk tagging)
- Dark mode theme

---

## Dependencies

### hippo-core

```toml
[dependencies]
tokio = { version = "1", features = ["full"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
uuid = { version = "1", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
thiserror = "1"
anyhow = "1"

# Storage
rusqlite = { version = "0.32", features = ["bundled"] }
qdrant-client = "1.12"

# Indexing
walkdir = "2"
mime_guess = "2"
rayon = "1"

# Metadata
image = "0.25"
exif = "0.6"
symphonia = { version = "0.5", features = ["all"] }

# Thumbnails
pdfium-render = "0.8"
zip = "2"
sha2 = "0.10"
lru = "0.12"
parking_lot = "0.12"

# AI
reqwest = { version = "0.12", features = ["json", "stream"] }
futures-util = "0.3"
tokio-util = "0.7"
base64 = "0.22"

# File watching
notify = "7"

# Utilities
directories = "5"
num_cpus = "1"
tracing = "0.1"
regex = "1"
```

### hippo-tauri

```toml
[dependencies]
tauri = { version = "2.1", features = [] }
tauri-plugin-dialog = "2"
tauri-plugin-fs = "2"
tauri-plugin-shell = "2"
hippo-core = { path = "../hippo-core" }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
tokio = { version = "1", features = ["full"] }
tracing = "0.1"
directories = "5"
```

---

## Running the App

### Development

```bash
cd hippo-tauri
cargo run
```

### Production Build

```bash
cd hippo-tauri
cargo tauri build
```

**Database locations**:
- macOS: `~/Library/Application Support/Hippo/hippo.db`
- Linux: `~/.local/share/Hippo/hippo.db`
- Windows: `%APPDATA%\Hippo\hippo.db`

**Cache locations**:
- Thumbnails: `~/.cache/Hippo/thumbnails/` (Linux/macOS)
- Qdrant data: `<data_dir>/qdrant/`

---

## Key Files Reference

| Feature | File(s) |
|---------|---------|
| Add new file types | `hippo-core/src/indexer/mod.rs` (SUPPORTED_EXTENSIONS) |
| Metadata extraction | `hippo-core/src/indexer/extractors.rs` |
| Code language support | `hippo-core/src/indexer/code_parser.rs` |
| Search logic | `hippo-core/src/search/mod.rs` |
| Storage schema | `hippo-core/src/storage/mod.rs` (init_schema) |
| Vector search | `hippo-core/src/qdrant/mod.rs` |
| AI integration | `hippo-core/src/ollama/mod.rs` |
| File watching | `hippo-core/src/watcher/mod.rs` |
| Thumbnails | `hippo-core/src/thumbnails/mod.rs` |
| New Tauri commands | `hippo-tauri/src/main.rs` |
| UI changes | `hippo-tauri/ui/dist/index.html` |
| Data models | `hippo-core/src/models.rs` |
| Error types | `hippo-core/src/error.rs` |

---

## Next Steps to Consider

### Features
- Favorites view (starred files)
- Collections/Albums (manual grouping)
- Timeline view (chronological visualization)
- Duplicate file manager with merge UI
- Advanced filters UI (size, date ranges, etc.)
- Export search results to JSON/CSV
- Batch rename/move files
- File version history
- Quick Look preview panel

### Technical Improvements
- FTS5 full-text search for documents
- Incremental indexing (only changed files)
- Background thumbnail generation queue
- Streaming search results (paginated)
- Custom embedding models via ONNX
- Graph database for connections (Neo4j?)
- Desktop notifications for indexing
- macOS Spotlight integration
- Windows Search integration

### AI Enhancements
- Multi-modal search (text + image query)
- Smart collections (AI-grouped files)
- Auto-organize suggestions
- Conversation-based search
- File summarization on hover
- Automatic caption generation for all images

---

## Architecture Diagrams

### System Overview

```mermaid
graph TB
    subgraph "Frontend (Tauri)"
        UI[HTML/JS UI]
    end

    subgraph "Backend (Rust)"
        API[Hippo Core API]

        subgraph "Indexing Layer"
            IDX[Indexer]
            EXT[Extractors]
            PARSER[Code Parser]
        end

        subgraph "Storage Layer"
            SQL[(SQLite)]
            QD[(Qdrant)]
        end

        subgraph "Search Layer"
            SRCH[Searcher]
            EMB[Embedder]
        end

        subgraph "AI Layer"
            OLL[Ollama Client]
            CLAUDE[Claude Client]
        end

        subgraph "Utilities"
            THUMB[Thumbnails]
            WATCH[File Watcher]
            DUP[Duplicates]
        end
    end

    UI <-->|IPC| API

    API --> IDX
    IDX --> EXT
    IDX --> PARSER
    IDX --> SQL
    IDX --> EMB

    API --> SRCH
    SRCH --> SQL
    SRCH --> QD
    SRCH --> EMB

    EMB --> OLL

    API --> WATCH
    WATCH --> SQL

    API --> THUMB
    API --> DUP

    style UI fill:#e1f5ff
    style API fill:#fff9c4
    style SQL fill:#c8e6c9
    style QD fill:#c8e6c9
    style OLL fill:#ffe0b2
```

---

This documentation is comprehensive and up-to-date as of the current codebase. For questions or contributions, refer to the individual module source files for implementation details.

---

## Current Work In Progress (December 2025)

### Latest Checkpoint (December 25, 2025 - Session 2)

**Commit**: `c6f5e37` on `main` branch - All PRs merged through #38

**Latest Changes - Search UX & Keyboard Shortcuts (PR #38)**:
- âœ… Search input debouncing (300ms delay to reduce backend calls)
- âœ… Keyboard shortcuts help modal (press `?` to open)
- âœ… New keyboard shortcuts: `/`, `G`, `L`, `Cmd+,`, `Cmd+F`, `Cmd+D`, `Cmd+A`, `Cmd+O`
- âœ… Shortcuts button with keyboard icon in sidebar footer
- âœ… Updated search placeholder with "/" shortcut hint
- âœ… CSS animations for search loading states
- âœ… Click-outside-to-close for shortcut help modal

**New Keyboard Shortcuts Available**:
| Shortcut | Action |
|----------|--------|
| `?` | Open keyboard shortcuts help |
| `/` | Focus search input (quick search) |
| `G` | Switch to grid view |
| `L` | Switch to list view |
| `Cmd+,` | Open settings |
| `Cmd+F` | Focus search |
| `Cmd+D` | Toggle dark mode |
| `Cmd+A` | Select all files |
| `Cmd+O` | Add folder |
| `Cmd+K` | Command palette |
| `Esc` | Close modals / Deselect |
| `Tab` | Convert search text to tag filter |

**Previous Session - Performance Optimizations (PR #36, #37)**:
- âœ… SQLite: 1GB cache, 1GB mmap, WAL optimizations (5-10x faster queries)
- âœ… Search cache: 500 entries with 60s TTL (2-3x better hit rate)
- âœ… Levenshtein: Single-row algorithm with early termination (3-5x faster)
- âœ… Hybrid search: Parallel semantic + keyword via tokio::join! (40-50% faster)
- âœ… Indexer: 16-core parallelism, 200-file batches (1.5-2x faster)
- âœ… Ollama: 5000 embedding cache, 15-min model cache, 10-min streaming timeout
- âœ… Thumbnails: 2000 LRU entries, 100MB memory limit (2-4x hit rate)
- âœ… Updated app icons with proper hippo mascot
- âœ… Version bumped to 0.2.0

**AI Quality Improvements**:
- âœ… Switched default model to `gemma2:2b` (better quality/speed ratio)
- âœ… Improved RAG with semantic search for context retrieval
- âœ… Increased context size from 1.5K to 20K+ chars
- âœ… Enhanced prompts for better AI responses
- âœ… Lower temperature (0.3) for more focused answers
- âœ… Increased token limit (2048) for detailed responses

### Current AI Configuration

**Default Models (No API Key Required)**:
- **Embeddings**: `nomic-embed-text` (768-dim, local via Ollama)
- **Generation**: `gemma2:2b` (~1.6GB, excellent quality/speed)
- **Vision/Image**: `llava:7b` (image captioning and analysis)

**Installed Models (Recommended)**:
```bash
ollama pull nomic-embed-text  # Required for semantic search
ollama pull gemma2:2b         # Default generation model
ollama pull llava:7b          # Optional for image analysis
```

**Model Priority List (quality-focused)**:
1. `gemma2:2b` - Default, best quality/speed balance
2. `llama3.2:3b` - Great quality, slightly larger
3. `qwen2.5:1.5b` - Very fast alternative
4. `llama3.2:1b` - Fastest but lower quality

### Working Features

| Feature | Status | Notes |
|---------|--------|-------|
| File indexing | âœ… Working | 70+ file types supported |
| Text search | âœ… Working | Fast SQL-based search |
| Tag filtering | âœ… Working | Include/exclude modes |
| Semantic search | âœ… Working | Vector similarity via Qdrant |
| File watcher | âœ… Working | Auto-starts on init, uses notify crate |
| Thumbnails | âœ… Working | Images, videos, PDFs |
| AI Chat (RAG) | âœ… Improved | Semantic context retrieval |
| Image captions | âœ… Working | llava:7b model |
| Code parsing | âœ… Working | Rust, Python, JS, Go |
| Auto-tagging | âœ… Enabled | Default on with Ollama |
| Code preview | âœ… Working | Prism.js syntax highlighting |

### Completed (Recent Sessions)

#### System-Wide Performance Optimizations (December 25, 2025)
- âœ… SQLite: Increased cache to 1GB, mmap to 1GB, added WAL optimizations
- âœ… Search: 500-entry cache with 60s TTL, parallel hybrid search
- âœ… Algorithms: Optimized Levenshtein (single-row + early termination)
- âœ… Indexer: Up to 16-core parallelism, 200-file batch size
- âœ… Ollama: 5000 embedding cache, extended timeouts, TCP_NODELAY
- âœ… Thumbnails: 2000 LRU entries, 100MB memory limit

#### AI Quality Improvements
- âœ… Switched to `gemma2:2b` for better responses
- âœ… RAG now uses semantic search to find relevant documents
- âœ… Context includes file content, tags, and metadata
- âœ… Improved system prompts with clear instructions
- âœ… Responses reference actual filenames

#### Code Features in UI
- âœ… Added Prism.js for syntax highlighting (20+ languages)
- âœ… Added code preview panel in detail view
- âœ… Auto-detects language from file extension

#### CI/CD Optimization
- âœ… Parallelized CI into 3 jobs (lint, test, build-check)
- âœ… Added ci-success aggregation job
- âœ… Caching for faster builds

#### Documentation (December 25, 2025)
- âœ… Created comprehensive CLI tutorial (`docs/CLI_TUTORIAL.md`)
- âœ… Created full feature list (`docs/FEATURES.md`)
- âœ… Created brand guide with colors, typography (`docs/BRAND_GUIDE.md`)
- âœ… Created mobile app architecture plan (`docs/MOBILE_APP.md`)
- âœ… Created SVG icon (`assets/hippo-icon.svg`)

### New Documentation

| Document | Description |
|----------|-------------|
| `docs/CLI_TUTORIAL.md` | Complete CLI guide with all 14 commands and examples |
| `docs/FEATURES.md` | Full feature matrix (70+ features documented) |
| `docs/BRAND_GUIDE.md` | Colors, typography, iconography, voice & tone |
| `docs/MOBILE_APP.md` | Mobile app architecture (React Native + Rust) |
| `assets/hippo-icon.svg` | Vector logo/icon |

### CLI Commands Reference

| Command | Aliases | Description |
|---------|---------|-------------|
| `chomp` | eat, index, add | Index a folder |
| `sniff` | search, find, s | Search files |
| `remember` | list, ls | List memories |
| `weight` | stats, info | Show statistics |
| `herd` | sources, folders | List sources |
| `mark` | tag | Add tags |
| `twins` | duplicates, dupes | Find duplicates |
| `brain` | ai, organize | AI auto-organize |
| `splash` | refresh, reindex | Reindex all |
| `stomp` | remove, rm | Remove source |
| `yawn` | open, reveal | Open in Finder |
| `wade` | watch | Watch changes |
| `den` | config, home | Show config |
| `forget` | reset, clear | Clear all |

---

## Elite Project Roadmap ðŸš€

### Phase 1: Polish & Stability (Current Focus)
- [ ] Add loading states and skeleton UI during searches
- [ ] Implement proper error boundaries in UI
- [ ] Add keyboard shortcuts cheat sheet (Cmd+/)
- [ ] Improve onboarding experience for new users
- [ ] Add dark mode theme toggle

### Phase 2: Advanced Search & Discovery
- [ ] Natural language date parsing ("files from last week")
- [ ] Saved searches / smart folders
- [ ] Search history with quick access
- [ ] Duplicate file detection UI with merge options
- [ ] Similar file clusters visualization

### Phase 3: AI Enhancements
- [ ] Streaming AI responses (real-time typing effect)
- [ ] AI-powered file organization suggestions
- [ ] Batch AI analysis for selected files
- [ ] Custom prompt templates for power users
- [ ] Multi-modal search (text + image query)

### Phase 4: Collaboration & Cloud
- [ ] Google Drive integration
- [ ] iCloud Drive integration
- [ ] Dropbox integration
- [ ] S3 bucket integration
- [ ] Shareable search links

### Phase 5: Advanced Visualization
- [ ] Knowledge graph with D3.js
- [ ] Timeline view for temporal exploration
- [ ] Geographic map for geotagged photos
- [ ] File relationship explorer
- [ ] Statistics dashboard

### Quality Checklist for Elite Status
- [ ] 90%+ test coverage on hippo-core
- [ ] Performance benchmarks documented
- [ ] Comprehensive API documentation
- [ ] User guide with screenshots
- [ ] Video tutorials for key features
- [ ] Accessibility audit (WCAG 2.1)
- [ ] Security audit for file handling
- [ ] Memory profiling and optimization
- [ ] Bundle size optimization for UI

### Commands for Testing

```bash
# Build everything
cargo build --workspace

# Run tests
cargo test --workspace

# Run Tauri app
cargo tauri dev

# Run CLI
cargo run -p hippo-cli -- --help

# Run web server
cargo run -p hippo-web
```

### Database Locations
- **macOS**: `~/Library/Application Support/Hippo/hippo.db`
- **Qdrant data**: `~/Library/Application Support/com.hippo.app/qdrant/`
- **Thumbnails**: `~/.cache/Hippo/thumbnails/`
